{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 787,
     "status": "ok",
     "timestamp": 1543360630388,
     "user": {
      "displayName": "Zaid Yahya",
      "photoUrl": "https://lh3.googleusercontent.com/-yftv3eJwV9g/AAAAAAAAAAI/AAAAAAAAABA/QiSM4ntrZIA/s64/photo.jpg",
      "userId": "02952936274959417276"
     },
     "user_tz": 300
    },
    "id": "tZPoMEn_xvoZ",
    "outputId": "75a4af88-a013-4ef3-d3b8-76c05474b74a"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from skimage.feature import hog\n",
    "from skimage import color\n",
    "from sklearn.cluster import KMeans\n",
    "import cv2\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqYy1yBXyMVT"
   },
   "outputs": [],
   "source": [
    "dataPath = 'all'\n",
    "localPath = ''\n",
    "\n",
    "images = np.load(dataPath + '/train_images.npy', encoding=\"bytes\")\n",
    "labels = pd.read_csv(dataPath + '/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tIeE3E3iyOoJ"
   },
   "outputs": [],
   "source": [
    "allData = pd.DataFrame(np.array(list(images[:,1]))).assign(label=labels['Category'])\n",
    "num_classes = len(labels['Category'].unique())\n",
    "valueCounts = labels['Category'].value_counts()\n",
    "\n",
    "\n",
    "xTrain, xValid = train_test_split(allData, stratify=labels['Category'], test_size=0.15)\n",
    "trainInds = xTrain.index\n",
    "validInds = xValid.index\n",
    "xTrainRaw = xTrain.drop('label', axis=1).values.reshape((xTrain.shape[0], 100, 100, 1))\n",
    "xValidRaw = xValid.drop('label', axis=1).values.reshape((xValid.shape[0], 100, 100, 1))\n",
    "\n",
    "yTrain = labels.iloc[trainInds, 1].values\n",
    "yValid = labels.iloc[validInds, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BH4kyRULs-TX"
   },
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "lb.fit(labels['Category'].unique())\n",
    "yTrainFinal = lb.transform(yTrain)\n",
    "yValidFinal = lb.transform(yValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MiiPWWWMyRgb"
   },
   "outputs": [],
   "source": [
    "def preProcessImage(image, cutoff=127, areaCutoff=14, maxContours=4, fliplr=False):\n",
    "    image = np.uint8(image)\n",
    "    im = np.uint8(image)\n",
    "    red, thresh = cv2.threshold(im, cutoff, 255, 0)\n",
    "    im2, contours, hierarchy= cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask = np.zeros(im.shape, np.uint8)\n",
    "    largest_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    \n",
    "    for ind, contour in enumerate(largest_contours[:maxContours]):\n",
    "        if cv2.contourArea(contour) > areaCutoff:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            mask[y:y+h, x:x+w] = 255\n",
    "        \n",
    "    filteredImage = cv2.bitwise_and(image, image, mask=mask)\n",
    "    if fliplr:\n",
    "        return np.fliplr(filteredImage).reshape((image.shape))\n",
    "    return filteredImage.reshape((image.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mae4zic6yV4i"
   },
   "outputs": [],
   "source": [
    "pool = ThreadPool(multiprocessing.cpu_count())\n",
    "xTrainUnflipped = pool.map(lambda im: preProcessImage(im).flatten(), [xTrainRaw[i] for i in range(xTrainRaw.shape[0])])\n",
    "xTrainUnflipped = np.array(xTrainUnflipped)\n",
    "\n",
    "xValidUnflipped = pool.map(lambda im: preProcessImage(im).flatten(), [xValidRaw[i] for i in range(xValidRaw.shape[0])])\n",
    "xValidUnflipped = np.array(xValidUnflipped)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pSW1QIGzbDzZ"
   },
   "source": [
    "**SIFT feature extraction and constructing BoVW (bag of visual words)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vzyOBo7zgFQ"
   },
   "outputs": [],
   "source": [
    "extractor = cv2.xfeatures2d.SIFT_create();\n",
    "def features(image, extractor):\n",
    "    keypoints, descriptors = extractor.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "dict_size = 8000;\n",
    "\n",
    "# !pip install opencv-python==3.4.2.16    #for installation on google colab\n",
    "# !pip install opencv-contrib-python==3.4.2.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edXZrObVzWKj"
   },
   "outputs": [],
   "source": [
    "descriptor_list = np.array([]);\n",
    "desc_src_img = [];\n",
    "      \n",
    "for i in range(0, len(xTrainUnflipped)):\n",
    "  im1 = xTrainUnflipped[i];\n",
    "  im1 = im1.reshape(100,100);\n",
    "  kp, dp = features(im1, extractor);\n",
    "  if dp is not None:\n",
    "    if len(descriptor_list) == 0 :\n",
    "      descriptor_list = np.array(dp);\n",
    "    else:\n",
    "      descriptor_list = np.vstack((descriptor_list, dp))\n",
    "    for j in range(len(dp)):\n",
    "      desc_src_img.append(i);\n",
    "        \n",
    "descriptor_list = np.float32(descriptor_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T3jaS6P0UVid"
   },
   "outputs": [],
   "source": [
    "#Array to hold all images, and later update pixels depending on which class they fall in after k-clustering\n",
    "imgs_data = [];\n",
    "for i in range(0, 8500):\n",
    "  imgs_data.insert(i, np.zeros((dict_size,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E0_xcx9eGQI9"
   },
   "outputs": [],
   "source": [
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "\n",
    "flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "\n",
    "compactness,labels,centers = cv2.kmeans(descriptor_list, dict_size, None, criteria, 1, flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMxYyQwTbIx4"
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(labels)):\n",
    "  img_id = desc_src_img[i];\n",
    "  imgs_data[img_id][labels[i]] += 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACb3mjtUqIg2"
   },
   "outputs": [],
   "source": [
    "xTrain = []\n",
    "for i in range(0, 8500):\n",
    "  xTrain.append(imgs_data[i])\n",
    "\n",
    "xTrain = np.asarray(xTrain);\n",
    "xTrain = xTrain.reshape(8500,dict_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZWQ42SsqXAy"
   },
   "outputs": [],
   "source": [
    "descriptor_list = np.array([]);\n",
    "desc_src_img = [];\n",
    "      \n",
    "for i in range(0, len(xValidUnflipped)):\n",
    "  im1 = xValidUnflipped[i];\n",
    "  im1 = im1.reshape(100,100);\n",
    "  kp, dp = features(im1, extractor);\n",
    "  if dp is not None:\n",
    "    if len(descriptor_list) == 0 :\n",
    "      descriptor_list = np.array(dp);\n",
    "    else:\n",
    "      descriptor_list = np.vstack((descriptor_list, dp))\n",
    "    for j in range(len(dp)):\n",
    "      desc_src_img.append(i);\n",
    "        \n",
    "descriptor_list = np.float32(descriptor_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBHLvhOBrvkX"
   },
   "outputs": [],
   "source": [
    "imgs_data = [];\n",
    "for i in range(0, 1500):\n",
    "  imgs_data.insert(i, np.zeros((dict_size,1)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rInxiCBtr406"
   },
   "outputs": [],
   "source": [
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "\n",
    "flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "\n",
    "compactness,labels,centers = cv2.kmeans(descriptor_list, dict_size, None, criteria, 1, flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fokVp133r-G7"
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(labels)):\n",
    "  img_id = desc_src_img[i];\n",
    "  imgs_data[img_id][labels[i]] += 1;\n",
    "\n",
    "xValid = []\n",
    "for i in range(0, 1500):\n",
    "  xValid.append(imgs_data[i])\n",
    "\n",
    "xValid = np.asarray(xValid);\n",
    "xValid = xValid.reshape(1500,dict_size);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGN1nvujc27Z"
   },
   "source": [
    "**Simple Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pWMDcNYB1B1R"
   },
   "outputs": [],
   "source": [
    "clf = SVC(gamma=.001)\n",
    "clf.fit(xTrain, yTrainFinal)\n",
    "\n",
    "y_pred = clf.predict(xValid)\n",
    "\n",
    "print(\"Accuracy: \"+str(accuracy_score(yValidFinal, y_pred)))\n",
    "print('\\n')\n",
    "print(classification_report(yValidFinal, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X1IijZjUcxi4"
   },
   "source": [
    "**Adaptive Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anCmKYP3cZ1d"
   },
   "outputs": [],
   "source": [
    "bdt = AdaBoostClassifier(SVC(gamma=.01, decision_function_shape='ovo'),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rdi3SjqOcjIo"
   },
   "outputs": [],
   "source": [
    "bdt.fit(xTrain, yTrainFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HdVQe-Iecol1"
   },
   "outputs": [],
   "source": [
    "y_pred = bdt.predict(xValid)\n",
    "print(\"Accuracy: \"+str(accuracy_score(yValidFinal, y_pred)))\n",
    "print('\\n')\n",
    "print(classification_report(yValidFinal, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "playsift.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
